{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanjeevmanvithvellala/engine-oil-health-prediction-IDEAS-2025/blob/main/Ideas_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44F0LeLdpz2F"
      },
      "source": [
        "#Dataset Loading and Basic Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WEv7FM5G4k6"
      },
      "source": [
        "The code explains how to load an engine oil dataset into a pandas DataFrame using read_csv(), which efficiently reads the CSV file into memory. It then outputs the shape of the dataset, indicating the total number of rows and columns, and displays the first few rows for initial inspection. Following this, it generates comprehensive summary statistics for all columns via the describe() method with include='all', providing insights into data distribution, central tendencies, and data types. These steps serve as a foundational process for exploring, understanding, and preparing data for further analysis or modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6pkFk1nTcR7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file_path = '/content/Engine_Oil.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Dataset shape and first few rows\n",
        "print(f'Dataset shape: {df.shape}')\n",
        "print(df.head())\n",
        "\n",
        "# Descriptive statistics for all columns\n",
        "summary_stats = df.describe(include='all')\n",
        "print(\"\\nSummary Statistics:\\n\")\n",
        "print(summary_stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQsdC6gtV0Ad"
      },
      "source": [
        "# Data Cleaning and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7hvkPIeHgMI"
      },
      "source": [
        "Now the next step involves a thorough assessment of data quality by examining the presence of missing values and duplicate entries. Missing values in critical numerical features are identified and subsequently imputed using the median to mitigate the effects of outliers. Following imputation, the dataset is reviewed again to ensure completeness. Duplicate records, which can distort analysis and modeling, are detected and removed. Finally, after cleansing, the refined dataset is previewed and saved for further processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1yWrYdJgVun1"
      },
      "outputs": [],
      "source": [
        "# 1. Identifying the missing values per column\n",
        "print(\"Missing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# 2. Imputing the missing values using median for numerical columns with missing data\n",
        "for col in ['lub_oil_pressure', 'fuel_pressure', 'lub_oil_temp']:\n",
        "    median_val = df[col].median()\n",
        "    df[col].fillna(median_val, inplace=True)\n",
        "\n",
        "# 3. Confirming the missing values have been handled\n",
        "print(\"Missing values after imputation:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# 4. Checking for duplicate rows and remove them\n",
        "num_duplicates = df.duplicated().sum()\n",
        "print(f\"Number of duplicate rows: {num_duplicates}\")\n",
        "\n",
        "if num_duplicates > 0:\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    print(f\"Duplicates dropped. New dataset shape: {df.shape}\")\n",
        "\n",
        "# 5. Showing the first few rows of clean dataset\n",
        "print(\"Cleaned dataset preview:\")\n",
        "print(df.head())\n",
        "\n",
        "# Saving cleaned dataset to file\n",
        "cleaned_file_path = 'Engine_Oil_Dataset_Cleaned.csv'\n",
        "df.to_csv(cleaned_file_path, index=False)\n",
        "print(f\"Cleaned dataset saved to {cleaned_file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTtQ1cWxwfnw"
      },
      "source": [
        "# Trend Analysis - Temperature, Pressure, RPM vs Oil Health\n",
        "\n",
        "Plotting basic trends to understand how temperature, pressure, and RPM relate to engine oil health.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vczk8O6wfnx"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load cleaned dataset\n",
        "df = pd.read_csv('Engine_Oil_Dataset_Cleaned.csv')\n",
        "\n",
        "# Create trend plots for temperature, pressure, RPM vs oil health\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# 1. Oil Temperature vs Oil Health\n",
        "axes[0, 0].scatter(df['lub_oil_temp'], df['engine_oil_health'], alpha=0.5, s=20)\n",
        "axes[0, 0].set_xlabel('Lubrication Oil Temperature (°C)')\n",
        "axes[0, 0].set_ylabel('Engine Oil Health')\n",
        "axes[0, 0].set_title('Oil Temperature vs Oil Health')\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Add trend line\n",
        "z = np.polyfit(df['lub_oil_temp'], df['engine_oil_health'], 1)\n",
        "p = np.poly1d(z)\n",
        "axes[0, 0].plot(df['lub_oil_temp'], p(df['lub_oil_temp']), \"r--\", alpha=0.8, linewidth=2)\n",
        "\n",
        "# 2. Oil Pressure vs Oil Health\n",
        "axes[0, 1].scatter(df['lub_oil_pressure'], df['engine_oil_health'], alpha=0.5, s=20, color='green')\n",
        "axes[0, 1].set_xlabel('Lubrication Oil Pressure')\n",
        "axes[0, 1].set_ylabel('Engine Oil Health')\n",
        "axes[0, 1].set_title('Oil Pressure vs Oil Health')\n",
        "axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "# Add trend line\n",
        "z = np.polyfit(df['lub_oil_pressure'], df['engine_oil_health'], 1)\n",
        "p = np.poly1d(z)\n",
        "axes[0, 1].plot(df['lub_oil_pressure'], p(df['lub_oil_pressure']), \"r--\", alpha=0.8, linewidth=2)\n",
        "\n",
        "# 3. Engine RPM vs Oil Health\n",
        "axes[1, 0].scatter(df['engine_rpm'], df['engine_oil_health'], alpha=0.5, s=20, color='orange')\n",
        "axes[1, 0].set_xlabel('Engine RPM')\n",
        "axes[1, 0].set_ylabel('Engine Oil Health')\n",
        "axes[1, 0].set_title('Engine RPM vs Oil Health')\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# Add trend line\n",
        "z = np.polyfit(df['engine_rpm'], df['engine_oil_health'], 1)\n",
        "p = np.poly1d(z)\n",
        "axes[1, 0].plot(df['engine_rpm'], p(df['engine_rpm']), \"r--\", alpha=0.8, linewidth=2)\n",
        "\n",
        "# 4. Box plot showing oil health distribution by health level\n",
        "health_counts = df['engine_oil_health'].value_counts().sort_index()\n",
        "axes[1, 1].bar(health_counts.index, health_counts.values, color='steelblue', alpha=0.7)\n",
        "axes[1, 1].set_xlabel('Engine Oil Health Level')\n",
        "axes[1, 1].set_ylabel('Frequency')\n",
        "axes[1, 1].set_title('Distribution of Oil Health Levels')\n",
        "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary statistics by health level\n",
        "print(\"\\n=== Summary Statistics by Oil Health Level ===\\n\")\n",
        "for health_level in sorted(df['engine_oil_health'].unique()):\n",
        "    subset = df[df['engine_oil_health'] == health_level]\n",
        "    print(f\"Health Level {health_level} (n={len(subset)}):\")\n",
        "    print(f\"  Avg Temperature: {subset['lub_oil_temp'].mean():.2f}°C\")\n",
        "    print(f\"  Avg Pressure: {subset['lub_oil_pressure'].mean():.2f}\")\n",
        "    print(f\"  Avg RPM: {subset['engine_rpm'].mean():.2f}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF1l_367WnFw"
      },
      "source": [
        "# Feature Selection and Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UnFpiNxmWnTX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Loading the cleaned dataset\n",
        "df = pd.read_csv('Engine_Oil_Dataset_Cleaned.csv')\n",
        "\n",
        "# Correlation matrix heatmap to identify key features correlated with target\n",
        "plt.figure(figsize=(10,8))\n",
        "corr_matrix = df.corr()\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Feature Correlation Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI6EaBVXwfnz"
      },
      "source": [
        "# Feature Engineering - Rolling Averages and Interaction Features\n",
        "\n",
        "Creating new features: rolling averages of temperature, pressure, RPM, and interaction feature (temp × RPM).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp5GwYyCwfnz",
        "outputId": "8838c187-9361-4888-d700-832c60cebd57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating rolling average features...\n",
            "Creating interaction features...\n",
            "\n",
            "New features created:\n",
            "  - temp_rolling_avg (rolling average of oil temperature)\n",
            "  - pressure_rolling_avg (rolling average of oil pressure)\n",
            "  - rpm_rolling_avg (rolling average of engine RPM)\n",
            "  - temp_x_rpm (temperature × RPM interaction)\n",
            "  - pressure_x_rpm (pressure × RPM interaction)\n",
            "  - temp_x_pressure (temperature × pressure interaction)\n",
            "\n",
            "Sample of new features:\n",
            "   lub_oil_temp  temp_rolling_avg   engine_rpm  rpm_rolling_avg    temp_x_rpm  \\\n",
            "0     83.996544         83.996544   717.062012       717.062012  60230.730702   \n",
            "1     77.593217         80.794881   896.794560       806.928286  69585.175337   \n",
            "2     77.759410         79.783057   514.330991       709.395855  39994.074452   \n",
            "3     74.167088         78.379065   464.032874       648.055109  34415.967186   \n",
            "4     78.450088         78.393269   616.926287       641.829345  48397.921289   \n",
            "5     76.573785         76.908718  1216.708111       741.758565  93167.945752   \n",
            "6     83.659981         78.122070   712.271411       704.853935  59588.612541   \n",
            "7     77.787175         78.127623   734.512247       748.890186  57135.632398   \n",
            "8     76.317430         78.557692   837.763497       823.636310  63935.957207   \n",
            "9     76.924092         78.252493   844.862391       869.223531  64990.272254   \n",
            "\n",
            "   engine_oil_health  \n",
            "0                  0  \n",
            "1                  0  \n",
            "2                  0  \n",
            "3                  4  \n",
            "4                  0  \n",
            "5                  0  \n",
            "6                  0  \n",
            "7                  3  \n",
            "8                  3  \n",
            "9                  0  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load cleaned dataset\n",
        "df = pd.read_csv('Engine_Oil_Dataset_Cleaned.csv')\n",
        "\n",
        "# Create a copy for feature engineering\n",
        "df_fe = df.copy()\n",
        "\n",
        "# Feature Engineering: Rolling Averages\n",
        "# Using window size of 5 for rolling averages\n",
        "window_size = 5\n",
        "\n",
        "print(\"Creating rolling average features...\")\n",
        "df_fe['temp_rolling_avg'] = df_fe['lub_oil_temp'].rolling(window=window_size, min_periods=1).mean()\n",
        "df_fe['pressure_rolling_avg'] = df_fe['lub_oil_pressure'].rolling(window=window_size, min_periods=1).mean()\n",
        "df_fe['rpm_rolling_avg'] = df_fe['engine_rpm'].rolling(window=window_size, min_periods=1).mean()\n",
        "\n",
        "# Feature Engineering: Interaction Features\n",
        "print(\"Creating interaction features...\")\n",
        "df_fe['temp_x_rpm'] = df_fe['lub_oil_temp'] * df_fe['engine_rpm']\n",
        "df_fe['pressure_x_rpm'] = df_fe['lub_oil_pressure'] * df_fe['engine_rpm']\n",
        "df_fe['temp_x_pressure'] = df_fe['lub_oil_temp'] * df_fe['lub_oil_pressure']\n",
        "\n",
        "# Display new features\n",
        "print(\"\\nNew features created:\")\n",
        "print(f\"  - temp_rolling_avg (rolling average of oil temperature)\")\n",
        "print(f\"  - pressure_rolling_avg (rolling average of oil pressure)\")\n",
        "print(f\"  - rpm_rolling_avg (rolling average of engine RPM)\")\n",
        "print(f\"  - temp_x_rpm (temperature × RPM interaction)\")\n",
        "print(f\"  - pressure_x_rpm (pressure × RPM interaction)\")\n",
        "print(f\"  - temp_x_pressure (temperature × pressure interaction)\")\n",
        "\n",
        "# Display sample of new features\n",
        "print(\"\\nSample of new features:\")\n",
        "print(df_fe[['lub_oil_temp', 'temp_rolling_avg', 'engine_rpm', 'rpm_rolling_avg',\n",
        "             'temp_x_rpm', 'engine_oil_health']].head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d4MIH5Wwfnz"
      },
      "source": [
        "Reviewing feature relevance via correlation analysis with new engineered features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tc680Blrwfn0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate correlation with target for all features including new ones\n",
        "correlation_features = ['lub_oil_temp', 'temp_rolling_avg',\n",
        "                        'lub_oil_pressure', 'pressure_rolling_avg',\n",
        "                        'engine_rpm', 'rpm_rolling_avg',\n",
        "                        'temp_x_rpm', 'pressure_x_rpm', 'temp_x_pressure',\n",
        "                        'fuel_pressure', 'coolant_pressure',\n",
        "                        'thermal_degradation_proxy', 'engine_condition']\n",
        "\n",
        "# Calculate correlations with target\n",
        "correlations = {}\n",
        "for feature in correlation_features:\n",
        "    if feature in df_fe.columns:\n",
        "        corr = df_fe[feature].corr(df_fe['engine_oil_health'])\n",
        "        correlations[feature] = corr\n",
        "\n",
        "# Sort by absolute correlation\n",
        "correlations_sorted = dict(sorted(correlations.items(), key=lambda x: abs(x[1]), reverse=True))\n",
        "\n",
        "print(\"Feature Correlation with Engine Oil Health:\")\n",
        "print(\"=\" * 60)\n",
        "for feature, corr in correlations_sorted.items():\n",
        "    print(f\"{feature:30s}: {corr:7.4f}\")\n",
        "\n",
        "# Visualize correlations\n",
        "plt.figure(figsize=(12, 8))\n",
        "features_list = list(correlations_sorted.keys())\n",
        "corr_values = [correlations_sorted[f] for f in features_list]\n",
        "colors = ['red' if x < 0 else 'green' for x in corr_values]\n",
        "\n",
        "plt.barh(features_list, corr_values, color=colors, alpha=0.7)\n",
        "plt.xlabel('Correlation with Engine Oil Health')\n",
        "plt.title('Feature Correlation Analysis (Including Engineered Features)')\n",
        "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
        "plt.grid(True, alpha=0.3, axis='x')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nTop 3 most correlated features (excluding target):\")\n",
        "top_3 = list(correlations_sorted.items())[:3]\n",
        "for i, (feature, corr) in enumerate(top_3, 1):\n",
        "    print(f\"{i}. {feature}: {corr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVRdJr8zIOVQ"
      },
      "source": [
        "Based on the correlation analysis and domain knowledge, a subset of relevant features is selected for modeling, along with the target variable representing engine oil health. The feature set and target are extracted from the dataset accordingly. Subsequently, the distribution of each selected feature is visualized using histograms with kernel density estimation to assess their statistical characteristics, including central tendency and skewness. This comprehensive visualization aids in understanding feature behavior and informs necessary preprocessing. The layout automatically adjusts, removing any unused subplot spaces for a clean presentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FylAvRYXEn-"
      },
      "outputs": [],
      "source": [
        "# Selecting features based on correlation & domain knowledge\n",
        "features = ['engine_rpm', 'lub_oil_pressure', 'fuel_pressure',\n",
        "            'coolant_pressure', 'lub_oil_temp', 'thermal_degradation_proxy',\n",
        "            'engine_condition']\n",
        "\n",
        "target = 'engine_oil_health'\n",
        "\n",
        "X = df[features]\n",
        "y = df[target]\n",
        "\n",
        "# Visualizing distribution of each feature in a grid\n",
        "n_features = len(features)\n",
        "n_cols = 3\n",
        "n_rows = (n_features + n_cols - 1) // n_cols\n",
        "\n",
        "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 5))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, feature in enumerate(features):\n",
        "    sns.histplot(X[feature], kde=True, ax=axes[i])\n",
        "    axes[i].set_title(f'Distribution of {feature}')\n",
        "    axes[i].set_xlabel(feature)\n",
        "    axes[i].set_ylabel('Frequency')\n",
        "\n",
        "# Hiding any unused subplots\n",
        "for j in range(i + 1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxreQRKLwfn0"
      },
      "source": [
        "# Identifying Top 3 Most Important Features\n",
        "\n",
        "Extracting and displaying the top 3 most important features from the Random Forest model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsPaPB0bXQOm",
        "outputId": "8ba697ef-8987-4e75-9d2a-5217d6df416f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features: ['engine_rpm', 'lub_oil_pressure', 'fuel_pressure', 'coolant_pressure', 'lub_oil_temp', 'thermal_degradation_proxy', 'engine_condition']\n",
            "Target: engine_oil_health\n"
          ]
        }
      ],
      "source": [
        "# Saving feature and target data for next modeling steps\n",
        "X.to_csv('features_engine_oil.csv', index=False)\n",
        "y.to_csv('target_engine_oil.csv', index=False)\n",
        "\n",
        "print('Selected features:', features)\n",
        "print('Target:', target)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data (using original features for this analysis)\n",
        "X = pd.read_csv('features_engine_oil.csv')\n",
        "y = pd.read_csv('target_engine_oil.csv').values.ravel()\n",
        "\n",
        "# Train Random Forest model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = pd.DataFrame({\n",
        "    'feature': X.columns,\n",
        "    'importance': rf_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"FEATURE IMPORTANCE ANALYSIS (Random Forest)\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nAll Features (sorted by importance):\")\n",
        "print(\"-\" * 60)\n",
        "for idx, row in feature_importances.iterrows():\n",
        "    print(f\"{row['feature']:35s}: {row['importance']:.6f}\")\n",
        "\n",
        "# Extract top 3 features\n",
        "top_3_features = feature_importances.head(3)\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TOP 3 MOST IMPORTANT FEATURES:\")\n",
        "print(\"=\" * 60)\n",
        "for i, (idx, row) in enumerate(top_3_features.iterrows(), 1):\n",
        "    print(f\"{i}. {row['feature']:35s}: {row['importance']:.6f} ({row['importance']*100:.2f}%)\")\n",
        "\n",
        "# Visualize feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=feature_importances, y='feature', x='importance', palette='viridis')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Random Forest - Feature Importance Rankings')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Highlight top 3 in a separate plot\n",
        "plt.figure(figsize=(10, 4))\n",
        "colors = ['gold' if f in top_3_features['feature'].values else 'steelblue'\n",
        "          for f in feature_importances['feature']]\n",
        "sns.barplot(data=feature_importances, y='feature', x='importance', palette=colors)\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Feature Importance (Top 3 Highlighted in Gold)')\n",
        "plt.axvline(x=top_3_features['importance'].iloc[2], color='red', linestyle='--',\n",
        "            alpha=0.5, label='Top 3 threshold')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SUMMARY:\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Top 3 features account for {top_3_features['importance'].sum()*100:.2f}% of total importance\")\n",
        "print(f\"These features are critical for predicting engine oil health.\")"
      ],
      "metadata": {
        "id": "yfmbpmBexrB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhEyvigWYDcY"
      },
      "source": [
        "# Model Recommendation and Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaKyopgDYzXG"
      },
      "source": [
        "## 1) Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psTM5EgcIg6X"
      },
      "source": [
        "The Random Forest model is trained on the unscaled training features, and predictions are made on the test set. Model performance is assessed using accuracy and root mean squared error metrics, providing insight into classification correctness and error magnitude. Finally, a confusion matrix is visualized through a heatmap, illustrating the model’s classification distribution across true and predicted classes, which aids in diagnosing prediction strengths and weaknesses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXf1A1n6YDm-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Load data\n",
        "X = pd.read_csv('features_engine_oil.csv')\n",
        "y = pd.read_csv('target_engine_oil.csv').values.ravel()\n",
        "\n",
        "# Split and scale\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Model training\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'Random Forest - Accuracy: {accuracy:.3f}, RMSE: {rmse:.3f}')\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Random Forest Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFflOD1lI3Rv"
      },
      "source": [
        "The Random Forest model achieved perfect accuracy (1.000) and zero root mean squared error (RMSE 0.000) on the test set, indicating flawless classification of engine oil health in this evaluation. This suggests the model fits the test data exceptionally well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOEOvO88ZaXT"
      },
      "source": [
        "## 2) Support Vector Machine (SVM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEevnOcKJKa8"
      },
      "source": [
        "Training a Support Vector Machine (SVM) classifier using the scaled training data, fitting the model with a fixed random state for reproducibility. The trained model predicts labels on the scaled test set. Its performance is evaluated using accuracy and root mean squared error (RMSE), quantifying classification correctness and error magnitude. A confusion matrix is then generated and visualized with a heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BlgLWhbEZawS"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Model training\n",
        "svm = SVC(random_state=42)\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "y_pred = svm.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'SVM - Accuracy: {accuracy:.3f}, RMSE: {rmse:.3f}')\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')\n",
        "plt.title('SVM Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6QbuvZdJYIG"
      },
      "source": [
        "The Support Vector Machine (SVM) classifier achieved an accuracy of 97.7% and an RMSE of 0.365 on the test dataset, indicating that it performs well in classifying engine oil health with high correctness and low prediction error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiw1IJAVaXEM"
      },
      "source": [
        "## 3) K-Nearest Neighbors (KNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tDOZ1l2Jfhd"
      },
      "source": [
        "Training a K-Nearest Neighbors (KNN) classifier on the scaled training data, then predicts labels for the scaled test data. Its performance is evaluated using accuracy and RMSE, providing measures of classification correctness and prediction error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBGC1Pj3aXOk"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Model training\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "y_pred = knn.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'KNN - Accuracy: {accuracy:.3f}, RMSE: {rmse:.3f}')\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Oranges')\n",
        "plt.title('KNN Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88qeL4R9Jprx"
      },
      "source": [
        "The K-Nearest Neighbors (KNN) classifier achieved an accuracy of 91.2% and an RMSE of 0.763 on the test set, indicating good classification performance with some margin of prediction error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBsSZXXcaj7B"
      },
      "source": [
        "## 4) Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDcKDWx9Jv-a"
      },
      "source": [
        "Training a Logistic Regression model on the scaled training features with a maximum iteration limit set to ensure convergence. After training, it predicts labels for the scaled test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1npQKD0faoAn"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Model training\n",
        "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "y_pred = lr.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'Logistic Regression - Accuracy: {accuracy:.3f}, RMSE: {rmse:.3f}')\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples')\n",
        "plt.title('Logistic Regression Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6yRvzCLJ5qu"
      },
      "source": [
        "The Logistic Regression model achieved an accuracy of 97.9% and an RMSE of 0.324 on the test data, indicating strong classification performance with low prediction error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRw1fTuQa51m"
      },
      "source": [
        "## 5) Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8mS6hzvKBaK"
      },
      "source": [
        "Training a Decision Tree classifier using the original, unscaled training data and predicts on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJx1iCrUa6F7"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Model training\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "print(f'Decision Tree - Accuracy: {accuracy:.3f}, RMSE: {rmse:.3f}')\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Reds')\n",
        "plt.title('Decision Tree Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtekMtRjKKtA"
      },
      "source": [
        "The Decision Tree model achieved perfect accuracy (1.000) and zero RMSE on the test set, indicating flawless classification performance for engine oil health."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N7-8SzDna5Y"
      },
      "source": [
        "## 6) Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FG0W7mkNKh0H"
      },
      "source": [
        "This segment develops a neural network for classifying engine oil health. The features are scaled for uniform input ranges, and the target labels are encoded using one-hot encoding for multi-class problems. The neural network is composed of two hidden layers with dropout for regularization, and the output layer adjusts its activation function depending on the number of classes. The model is compiled with an appropriate loss function and trained with early stopping to mitigate overfitting, monitoring validation loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcbZqAalnleh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load features and target\n",
        "X = pd.read_csv('features_engine_oil.csv')\n",
        "y = pd.read_csv('target_engine_oil.csv').values.ravel()\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Encode target if classification (>2 classes)\n",
        "num_classes = len(np.unique(y))\n",
        "if num_classes > 2:\n",
        "    y_encoded = to_categorical(y)\n",
        "else:\n",
        "    y_encoded = y\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax' if num_classes > 2 else 'sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='categorical_crossentropy' if num_classes > 2 else 'binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Early stopping to reduce overfitting\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32,\n",
        "                    validation_split=0.2, callbacks=[early_stop], verbose=2)\n",
        "\n",
        "# Evaluate on test set\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {scores[1]*100:.2f}%\")\n",
        "\n",
        "# Plotting training history\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vezSWjGIKzq1"
      },
      "source": [
        "The training process shows the neural network’s progressive learning over 36 epochs, starting with moderate training accuracy and rapidly improving validation accuracy, eventually reaching a high test accuracy of 99.49%. The early stopping callback likely halted further training to prevent overfitting, as validation loss stabilized or increased. This demonstrates strong model convergence and excellent predictive performance on the test set for engine oil health classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CulpEEh-bXIQ"
      },
      "outputs": [],
      "source": [
        "# Combined Summary\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load dataset\n",
        "X = pd.read_csv('features_engine_oil.csv')\n",
        "y = pd.read_csv('target_engine_oil.csv').values.ravel()\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define traditional ML models\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'SVM': SVC(random_state=42),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "# Train, predict, evaluate traditional models\n",
        "for name, model in models.items():\n",
        "    if name in ['SVM', 'KNN', 'Logistic Regression']:\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "    else:\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    results[name] = {'Accuracy': acc, 'RMSE': rmse}\n",
        "\n",
        "# Neural network model\n",
        "\n",
        "# One-hot encode target for multi-class classification\n",
        "num_classes = len(np.unique(y_train))\n",
        "y_train_encoded = to_categorical(y_train, num_classes)\n",
        "y_test_encoded = to_categorical(y_test, num_classes)\n",
        "\n",
        "nn_model = Sequential()\n",
        "nn_model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "nn_model.add(Dropout(0.2))\n",
        "nn_model.add(Dense(32, activation='relu'))\n",
        "nn_model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "nn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "nn_model.fit(X_train_scaled, y_train_encoded, epochs=50, batch_size=32, verbose=0)\n",
        "\n",
        "# Predict classes for test set\n",
        "y_pred_probs = nn_model.predict(X_test_scaled)\n",
        "y_pred_classes = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Metrics\n",
        "acc_nn = accuracy_score(y_test, y_pred_classes)\n",
        "mse_nn = mean_squared_error(y_test, y_pred_classes)\n",
        "rmse_nn = np.sqrt(mse_nn)\n",
        "results['Neural Network'] = {'Accuracy': acc_nn, 'RMSE': rmse_nn}\n",
        "\n",
        "# Prepare results DataFrame\n",
        "df_results = pd.DataFrame(results).T.reset_index().rename(columns={'index': 'Model'})\n",
        "\n",
        "# Plot accuracy comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Model', y='Accuracy', data=df_results, palette='viridis')\n",
        "plt.title('Model Accuracy Comparison')\n",
        "plt.ylim(0, 1)\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Model')\n",
        "for index, row in df_results.iterrows():\n",
        "    plt.text(index, row.Accuracy + 0.02, f\"{row.Accuracy:.2f}\", ha='center')\n",
        "plt.show()\n",
        "\n",
        "# Plot RMSE comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Model', y='RMSE', data=df_results, palette='magma')\n",
        "plt.title('Model RMSE Comparison')\n",
        "plt.ylabel('RMSE')\n",
        "plt.xlabel('Model')\n",
        "for index, row in df_results.iterrows():\n",
        "    plt.text(index, row.RMSE + 0.01, f\"{row.RMSE:.2f}\", ha='center')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHuOG0dndPoD"
      },
      "source": [
        "# Model Optimization and Final Recommendation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6LgJF8YL1_0"
      },
      "source": [
        "Performing hyperparameter tuning for a Random Forest classifier using RandomizedSearchCV on a 30% subset of the training data. It searches 20 parameter combinations with 3-fold cross-validation and prints the best hyperparameters and corresponding accuracy to optimize model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YROV8q0YdPxy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Load data\n",
        "X = pd.read_csv('features_engine_oil.csv')\n",
        "y = pd.read_csv('target_engine_oil.csv').values.ravel()\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Parameter distribution for randomized search\n",
        "param_dist = {\n",
        "    'n_estimators': stats.randint(100, 500),\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': stats.randint(2, 10),\n",
        "    'min_samples_leaf': stats.randint(1, 4),\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# RandomizedSearchCV setup\n",
        "rand_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=20, cv=3, random_state=42, n_jobs=-1, verbose=2)\n",
        "\n",
        "# Using subset of data for tuning (reduce to 30% training data)\n",
        "X_sample, _, y_sample, _ = train_test_split(X_train_scaled, y_train, test_size=0.7, random_state=42)\n",
        "\n",
        "# Fit randomized search on sample\n",
        "rand_search.fit(X_sample, y_sample)\n",
        "\n",
        "# Best parameters and score\n",
        "print(\"Best hyperparameters found:\", rand_search.best_params_)\n",
        "print(\"Best CV accuracy:\", rand_search.best_score_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxcTx2_7MDgb"
      },
      "source": [
        "The best hyperparameters identified are: no bootstrap sampling, no maximum depth constraint, minimum of 1 sample per leaf, minimum of 8 samples per split, and 221 estimators. This configuration achieved an exceptionally high cross-validation accuracy of approximately 99.91%, indicating optimal model performance under the tested parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y25v-zAUUkn8"
      },
      "source": [
        "Filtering/removing classes with fewer than 2 samples before splitting and modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kx2Wxns9S37c"
      },
      "outputs": [],
      "source": [
        "# Load your features and target\n",
        "X = pd.read_csv('features_engine_oil.csv')\n",
        "y = pd.read_csv('target_engine_oil.csv').values.ravel()\n",
        "\n",
        "# Identify classes with <2 samples\n",
        "unique, counts = np.unique(y, return_counts=True)\n",
        "class_counts = dict(zip(unique, counts))\n",
        "rare_classes = [c for c in class_counts if class_counts[c] < 2]\n",
        "print(\"Rare classes (to remove):\", rare_classes)\n",
        "\n",
        "# Filter out rows belonging to rare classes\n",
        "mask = ~pd.Series(y).isin(rare_classes)\n",
        "X_filtered = X[mask]\n",
        "y_filtered = y[mask]\n",
        "\n",
        "# Confirm new distribution\n",
        "unique, counts = np.unique(y_filtered, return_counts=True)\n",
        "print(\"Class distribution after filtering:\", dict(zip(unique, counts)))\n",
        "\n",
        "# Now you can safely split the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_filtered, y_filtered, test_size=0.2, stratify=y_filtered, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcFyClo4Udcs"
      },
      "source": [
        "Handling Imbalanced Classes for ALL Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjX1_9d-T00r"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.metrics import classification_report # Import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder # Import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical # Import to_categorical\n",
        "from tensorflow.keras.models import Sequential # Import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout # Import Dense and Dropout\n",
        "import numpy as np # Import numpy\n",
        "import pandas as pd # Import pandas\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler # Import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier # Import RandomForestClassifier\n",
        "from sklearn.svm import SVC # Import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier # Import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression # Import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier # Import DecisionTreeClassifier\n",
        "\n",
        "\n",
        "# Load dataset features and target\n",
        "X = pd.read_csv('features_engine_oil.csv')\n",
        "y = pd.read_csv('target_engine_oil.csv').values.ravel()\n",
        "\n",
        "# Remove rows where the target is 1\n",
        "X = X[y != 1]\n",
        "y = y[y != 1]\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'SVM': SVC(random_state=42),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    # Apply SMOTE to training data to balance minority classes for the current model\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "    if name in ['SVM', 'KNN', 'Logistic Regression']:\n",
        "        model.fit(X_train_resampled, y_train_resampled)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "    else:\n",
        "        model.fit(X_train_resampled, y_train_resampled)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "    print(f\"{name} classification report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Neural network model\n",
        "\n",
        "# Encode target variable using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_nn_encoded_labels = label_encoder.fit_transform(y_train) # Use y_train before resampling\n",
        "y_test_nn_encoded_labels = label_encoder.transform(y_test)\n",
        "\n",
        "# One-hot encode target for multi-class classification\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y_train_nn_encoded = to_categorical(y_train_nn_encoded_labels, num_classes=num_classes)\n",
        "y_test_nn_encoded = to_categorical(y_test_nn_encoded_labels, num_classes=num_classes)\n",
        "\n",
        "# Apply SMOTE to NN training data\n",
        "smote_nn = SMOTE(random_state=42)\n",
        "X_train_nn_resampled, y_train_nn_resampled = smote_nn.fit_resample(X_train_scaled, y_train_nn_encoded) # Use X_train_scaled and y_train_nn_encoded\n",
        "\n",
        "\n",
        "nn_model = Sequential()\n",
        "nn_model.add(Dense(64, input_dim=X_train_nn_resampled.shape[1], activation='relu'))\n",
        "nn_model.add(Dropout(0.2))\n",
        "nn_model.add(Dense(32, activation='relu'))\n",
        "nn_model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "nn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Using a small number of epochs for demonstration, you might need more for better results\n",
        "nn_model.fit(X_train_nn_resampled, y_train_nn_resampled, epochs=50, batch_size=32, verbose=0) # Use resampled data\n",
        "\n",
        "y_pred_probs_nn = nn_model.predict(X_test_scaled) # Use X_test_scaled for prediction\n",
        "y_pred_classes_nn = np.argmax(y_pred_probs_nn, axis=1)\n",
        "\n",
        "# Decode the predicted class labels back to original labels for evaluation\n",
        "y_pred_classes_nn_decoded = label_encoder.inverse_transform(y_pred_classes_nn)\n",
        "\n",
        "# Evaluate neural network performance using original labels\n",
        "print(\"Neural Network classification report:\\n\", classification_report(y_test, y_pred_classes_nn_decoded))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyE4cOZ-MrGW"
      },
      "source": [
        "SHAP (SHapley Additive exPlanations) is a method to explain individual predictions of complex machine learning models by computing the contribution of each feature using cooperative game theory principles. Using SHAP to interpret the neural network’s predictions on engine oil health data. It selects a background sample from the scaled training data and defines a prediction function for SHAP’s KernelExplainer. SHAP values are computed for 100 test samples to improve efficiency. The summary plot shows the impact of each feature across all classes, highlighting the most influential features for model predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOwmXXd0WKVj"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "\n",
        "# Select a small background sample for SHAP\n",
        "background = X_train_scaled[np.random.choice(X_train_scaled.shape[0], 100, replace=False)]\n",
        "\n",
        "# Define a prediction function returning model output probabilities\n",
        "def predict_fn(data):\n",
        "    # Ensure data is in the correct format (numpy array of float32)\n",
        "    data = np.array(data, dtype=np.float32)\n",
        "    # Return prediction probabilities with shape (n_samples, n_classes)\n",
        "    return nn_model.predict(data)\n",
        "\n",
        "# Create KernelExplainer with model prediction function and background data\n",
        "explainer = shap.KernelExplainer(predict_fn, background)\n",
        "\n",
        "# Compute SHAP values for a subset of test data for speed\n",
        "shap_values = explainer.shap_values(X_test_scaled[:100])\n",
        "\n",
        "# Plot summary for all classes using the list of SHAP value arrays\n",
        "shap.summary_plot(shap_values, X_test_scaled[:100], feature_names=X.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZZ065PFXOkW"
      },
      "source": [
        "# Model Serialization and Deployment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3g2LlzmscX7a"
      },
      "source": [
        "Stacking Ensemble Technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdYwVv_KNLDC"
      },
      "source": [
        "Implementing a stacking ensemble classifier combining Random Forest, SVM, and Gradient Boosting as base learners, with Logistic Regression as the meta-learner. After scaling the features and splitting the dataset into training and testing sets with stratification, the stacking model is trained using 5-fold cross-validation. Predictions on the test set are evaluated with accuracy, providing a robust combined model by leveraging the strengths of multiple classifiers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTq5wc3kcjEo"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming X, y are your dataset as DataFrame and Series/numpy arrays\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define base learners\n",
        "base_learners = [\n",
        "    ('rf', RandomForestClassifier(random_state=42)),\n",
        "    ('svm', SVC(probability=True, random_state=42)),\n",
        "    ('gb', GradientBoostingClassifier(random_state=42))\n",
        "]\n",
        "\n",
        "# Meta-learner\n",
        "meta_learner = LogisticRegression()\n",
        "\n",
        "# Create stacking classifier\n",
        "stack_model = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=5, n_jobs=-1)\n",
        "stack_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred = stack_model.predict(X_test_scaled)\n",
        "print(f\"Stacking model accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUmE3nmPNZAn"
      },
      "source": [
        "The stacking ensemble model achieved perfect accuracy (1.0000) on the test set, indicating flawless classification of engine oil health by effectively combining the strengths of Random Forest, SVM, and Gradient Boosting base learners through Logistic Regression as the meta-learner."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZATF_tTIcoEg"
      },
      "source": [
        " Boosting using XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkhEZ63DPXQl"
      },
      "source": [
        "Training an XGBoost classifier for multi-class classification of engine oil health using scaled features. It predicts on the test set and prints the accuracy, reflecting model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5RbM51KdW4i"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from imblearn.over_sampling import SMOTE # Import SMOTE\n",
        "from sklearn.preprocessing import LabelEncoder # Import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical # Import to_categorical\n",
        "from sklearn.metrics import accuracy_score # Import accuracy_score\n",
        "\n",
        "\n",
        "# Encode target variable using LabelEncoder for XGBoost\n",
        "label_encoder_xgb = LabelEncoder()\n",
        "y_train_xgb_encoded_labels = label_encoder_xgb.fit_transform(y_train)\n",
        "y_test_xgb_encoded_labels = label_encoder_xgb.transform(y_test)\n",
        "\n",
        "# Calculate num_classes after fitting the label encoder\n",
        "num_classes = len(label_encoder_xgb.classes_)\n",
        "\n",
        "# Train XGBoost model using encoded labels\n",
        "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=num_classes, random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
        "\n",
        "# Apply SMOTE to XGBoost training data (using integer labels for SMOTE)\n",
        "smote_xgb = SMOTE(random_state=42)\n",
        "X_train_scaled_resampled_xgb, y_train_resampled_xgb = smote_xgb.fit_resample(X_train_scaled, y_train_xgb_encoded_labels)\n",
        "\n",
        "\n",
        "# Train XGBoost model using resampled data\n",
        "xgb_model.fit(X_train_scaled_resampled_xgb, y_train_resampled_xgb)\n",
        "\n",
        "# Predict using encoded labels\n",
        "y_pred_encoded = xgb_model.predict(X_test_scaled)\n",
        "\n",
        "# Decode predicted labels back to original labels for evaluation\n",
        "y_pred = label_encoder_xgb.inverse_transform(y_pred_encoded)\n",
        "\n",
        "# Predict and evaluate using original labels\n",
        "print(f\"XGBoost model accuracy: {accuracy_score(y_test, y_pred):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBum3lV2RgGR"
      },
      "source": [
        "Saving all trained models and the scaler for future use. Scikit-learn models and the scaler are saved as pickle files using joblib."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D315ON4LhI2Z"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "from tensorflow.keras.models import save_model\n",
        "\n",
        "# Save scikit-learn models\n",
        "joblib.dump(rf, 'random_forest_model.pkl')\n",
        "joblib.dump(svm, 'svm_model.pkl')\n",
        "joblib.dump(knn, 'knn_model.pkl')\n",
        "joblib.dump(lr, 'logistic_regression_model.pkl')\n",
        "joblib.dump(dt, 'decision_tree_model.pkl')\n",
        "joblib.dump(stack_model, 'stacking_model.pkl')\n",
        "joblib.dump(scaler, 'scaler.pkl')\n",
        "\n",
        "# Save Keras/TensorFlow neural network\n",
        "save_model(nn_model, 'neural_network_model.h5')\n",
        "\n",
        "# Save XGBoost model\n",
        "xgb_model.save_model('xgboost_model.json')\n",
        "\n",
        "print(\"All models have been saved successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWixu3Y-wthx"
      },
      "outputs": [],
      "source": [
        "# Comprehensive Overfitting Prevention Techniques\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve, validation_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load data\n",
        "X = pd.read_csv('features_engine_oil.csv')\n",
        "y = pd.read_csv('target_engine_oil.csv').values.ravel()\n",
        "\n",
        "# Remove rare class\n",
        "X = X[y != 1]\n",
        "y = y[y != 1]\n",
        "\n",
        "# IMPORTANT: Split BEFORE applying SMOTE to prevent data leakage\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"OVERFITTING PREVENTION TECHNIQUES\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYcIW8BwwyeJ"
      },
      "source": [
        "Technique 1: Proper Train-Validation-Test Split\n",
        "\n",
        "Instead of just train-test split, we should use train-validation-test split to monitor overfitting during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnS1nzXtw0Nd"
      },
      "outputs": [],
      "source": [
        "# Technique 1: Train-Validation-Test Split\n",
        "print(\"\\n1. TRAIN-VALIDATION-TEST SPLIT\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Split training data further into train and validation sets\n",
        "X_train_split, X_val, y_train_split, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {X_train_split.shape[0]}\")\n",
        "print(f\"Validation set size: {X_val.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "movFwZwbw3bc"
      },
      "source": [
        "Technique 2: Regularized Random Forest (Reduce Model Complexity)\n",
        "\n",
        "Apply constraints to Random Forest to prevent overfitting:\n",
        "- Limit max_depth\n",
        "- Increase min_samples_split and min_samples_leaf\n",
        "- Reduce n_estimators if needed\n",
        "- Use max_features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NjnPsBGw_yE"
      },
      "outputs": [],
      "source": [
        "# Technique 2: Regularized Random Forest\n",
        "print(\"\\n2. REGULARIZED RANDOM FOREST\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_split)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Apply SMOTE AFTER splitting (only on training data)\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train_split)\n",
        "\n",
        "# Unregularized Random Forest (for comparison)\n",
        "rf_unregularized = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "rf_unregularized.fit(X_train_balanced, y_train_balanced)\n",
        "train_acc_unreg = accuracy_score(y_train_balanced, rf_unregularized.predict(X_train_balanced))\n",
        "val_acc_unreg = accuracy_score(y_val, rf_unregularized.predict(X_val_scaled))\n",
        "test_acc_unreg = accuracy_score(y_test, rf_unregularized.predict(X_test_scaled))\n",
        "\n",
        "# Regularized Random Forest\n",
        "rf_regularized = RandomForestClassifier(\n",
        "    n_estimators=100,          # Reduced from default\n",
        "    max_depth=10,              # Limit tree depth (prevents overfitting)\n",
        "    min_samples_split=20,       # Increased (prevents splitting on small samples)\n",
        "    min_samples_leaf=10,        # Increased (prevents leaf nodes with few samples)\n",
        "    max_features='sqrt',        # Use sqrt of features (reduces correlation)\n",
        "    bootstrap=True,             # Use bootstrapping\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf_regularized.fit(X_train_balanced, y_train_balanced)\n",
        "train_acc_reg = accuracy_score(y_train_balanced, rf_regularized.predict(X_train_balanced))\n",
        "val_acc_reg = accuracy_score(y_val, rf_regularized.predict(X_val_scaled))\n",
        "test_acc_reg = accuracy_score(y_test, rf_regularized.predict(X_test_scaled))\n",
        "\n",
        "print(f\"\\nUnregularized Random Forest:\")\n",
        "print(f\"  Train Accuracy: {train_acc_unreg:.4f}\")\n",
        "print(f\"  Validation Accuracy: {val_acc_unreg:.4f}\")\n",
        "print(f\"  Test Accuracy: {test_acc_unreg:.4f}\")\n",
        "print(f\"  Gap (Train-Val): {train_acc_unreg - val_acc_unreg:.4f}\")\n",
        "\n",
        "print(f\"\\nRegularized Random Forest:\")\n",
        "print(f\"  Train Accuracy: {train_acc_reg:.4f}\")\n",
        "print(f\"  Validation Accuracy: {val_acc_reg:.4f}\")\n",
        "print(f\"  Test Accuracy: {test_acc_reg:.4f}\")\n",
        "print(f\"  Gap (Train-Val): {train_acc_reg - val_acc_reg:.4f}\")\n",
        "\n",
        "# Smaller gap indicates less overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBv-Yg1-xL55"
      },
      "source": [
        "Technique 3: Regularized Decision Tree (Pruning)\n",
        "\n",
        "Apply constraints to Decision Tree to prevent overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYM1N21vxLfE"
      },
      "outputs": [],
      "source": [
        "# Technique 3: Regularized Decision Tree\n",
        "print(\"\\n3. REGULARIZED DECISION TREE\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Unregularized Decision Tree\n",
        "dt_unregularized = DecisionTreeClassifier(random_state=42)\n",
        "dt_unregularized.fit(X_train_balanced, y_train_balanced)\n",
        "train_acc_dt_unreg = accuracy_score(y_train_balanced, dt_unregularized.predict(X_train_balanced))\n",
        "val_acc_dt_unreg = accuracy_score(y_val, dt_unregularized.predict(X_val_scaled))\n",
        "test_acc_dt_unreg = accuracy_score(y_test, dt_unregularized.predict(X_test_scaled))\n",
        "\n",
        "# Regularized Decision Tree (Pruned)\n",
        "dt_regularized = DecisionTreeClassifier(\n",
        "    max_depth=8,               # Limit tree depth\n",
        "    min_samples_split=30,       # Minimum samples to split\n",
        "    min_samples_leaf=15,       # Minimum samples in leaf\n",
        "    max_features='sqrt',       # Limit features considered\n",
        "    ccp_alpha=0.01,            # Cost complexity pruning (additional regularization)\n",
        "    random_state=42\n",
        ")\n",
        "dt_regularized.fit(X_train_balanced, y_train_balanced)\n",
        "train_acc_dt_reg = accuracy_score(y_train_balanced, dt_regularized.predict(X_train_balanced))\n",
        "val_acc_dt_reg = accuracy_score(y_val, dt_regularized.predict(X_val_scaled))\n",
        "test_acc_dt_reg = accuracy_score(y_test, dt_regularized.predict(X_test_scaled))\n",
        "\n",
        "print(f\"\\nUnregularized Decision Tree:\")\n",
        "print(f\"  Train Accuracy: {train_acc_dt_unreg:.4f}\")\n",
        "print(f\"  Validation Accuracy: {val_acc_dt_unreg:.4f}\")\n",
        "print(f\"  Test Accuracy: {test_acc_dt_unreg:.4f}\")\n",
        "print(f\"  Gap (Train-Val): {train_acc_dt_unreg - val_acc_dt_unreg:.4f}\")\n",
        "\n",
        "print(f\"\\nRegularized Decision Tree:\")\n",
        "print(f\"  Train Accuracy: {train_acc_dt_reg:.4f}\")\n",
        "print(f\"  Validation Accuracy: {val_acc_dt_reg:.4f}\")\n",
        "print(f\"  Test Accuracy: {test_acc_dt_reg:.4f}\")\n",
        "print(f\"  Gap (Train-Val): {train_acc_dt_reg - val_acc_dt_reg:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWDGZtxWxQfq"
      },
      "source": [
        "Technique 4: Cross-Validation for Robust Evaluation\n",
        "\n",
        "Use k-fold cross-validation to get more reliable performance estimates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvVcdX-WxTd9"
      },
      "outputs": [],
      "source": [
        "# Technique 4: Cross-Validation\n",
        "print(\"\\n4. CROSS-VALIDATION EVALUATION\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# Combine train and validation for CV\n",
        "X_train_cv = np.vstack([X_train_scaled, X_val_scaled])\n",
        "y_train_cv = np.hstack([y_train_split, y_val])\n",
        "\n",
        "# Apply SMOTE to full training data\n",
        "smote_cv = SMOTE(random_state=42)\n",
        "X_train_cv_balanced, y_train_cv_balanced = smote_cv.fit_resample(X_train_cv, y_train_cv)\n",
        "\n",
        "# Regularized Random Forest with Cross-Validation\n",
        "rf_cv = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    min_samples_split=20,\n",
        "    min_samples_leaf=10,\n",
        "    max_features='sqrt',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# 5-fold stratified cross-validation\n",
        "cv_scores = cross_val_score(rf_cv, X_train_cv_balanced, y_train_cv_balanced,\n",
        "                            cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "                            scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "print(f\"\\nCross-Validation Scores (5-fold):\")\n",
        "for i, score in enumerate(cv_scores, 1):\n",
        "    print(f\"  Fold {i}: {score:.4f}\")\n",
        "print(f\"\\nMean CV Score: {cv_scores.mean():.4f} (±{cv_scores.std():.4f})\")\n",
        "print(f\"\\nThis gives a more reliable estimate of model performance.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8znsrmYJxXEI"
      },
      "source": [
        "Technique 5: Learning Curves (Diagnose Overfitting)\n",
        "\n",
        "Plot learning curves to visualize if the model is overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "himqPFxXxe9M"
      },
      "outputs": [],
      "source": [
        "# Technique 5: Learning Curves\n",
        "print(\"\\n5. LEARNING CURVES\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "# Use smaller sample for learning curves (faster)\n",
        "sample_size = min(5000, len(X_train_cv_balanced))\n",
        "X_sample = X_train_cv_balanced[:sample_size]\n",
        "y_sample = y_train_cv_balanced[:sample_size]\n",
        "\n",
        "# Create regularized Random Forest\n",
        "rf_lc = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    min_samples_split=20,\n",
        "    min_samples_leaf=10,\n",
        "    max_features='sqrt',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Generate learning curve data\n",
        "train_sizes, train_scores, val_scores = learning_curve(\n",
        "    rf_lc, X_sample, y_sample,\n",
        "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
        "    n_jobs=-1,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
        "    scoring='accuracy'\n",
        ")\n",
        "\n",
        "# Calculate mean and std\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "val_mean = np.mean(val_scores, axis=1)\n",
        "val_std = np.std(val_scores, axis=1)\n",
        "\n",
        "# Plot learning curves\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training Accuracy')\n",
        "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
        "plt.plot(train_sizes, val_mean, 'o-', color='red', label='Cross-Validation Accuracy')\n",
        "plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color='red')\n",
        "\n",
        "plt.xlabel('Training Set Size')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Learning Curves - Regularized Random Forest')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Check for overfitting signs\n",
        "gap = train_mean[-1] - val_mean[-1]\n",
        "print(f\"\\nFinal Training Accuracy: {train_mean[-1]:.4f}\")\n",
        "print(f\"Final CV Accuracy: {val_mean[-1]:.4f}\")\n",
        "print(f\"Gap: {gap:.4f}\")\n",
        "if gap > 0.05:\n",
        "    print(\"WARNING: Large gap indicates overfitting. Consider more regularization.\")\n",
        "else:\n",
        "    print(\"✓ Gap is acceptable - model generalizes well.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmI_kNsTwfol"
      },
      "source": [
        "# Alert Logic & Prototype Dashboard\n",
        "\n",
        "Defining health thresholds and building a simple dashboard showing health scores and alerts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfMpy_epwfol"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load data\n",
        "X = pd.read_csv('features_engine_oil.csv')\n",
        "y = pd.read_csv('target_engine_oil.csv').values.ravel()\n",
        "\n",
        "# Remove rare class if needed\n",
        "X = X[y != 1]\n",
        "y = y[y != 1]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train Random Forest model for predictions\n",
        "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# ========================================\n",
        "# ALERT LOGIC: Define Health Thresholds\n",
        "# ========================================\n",
        "print(\"=\" * 60)\n",
        "print(\"ALERT LOGIC - HEALTH THRESHOLDS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Define health thresholds based on oil health levels\n",
        "# Health levels: 0 = Excellent, 2 = Good, 3 = Fair, 4 = Poor\n",
        "HEALTH_THRESHOLDS = {\n",
        "    'excellent': 0,      # Health level 0 - No action needed\n",
        "    'good': 2,           # Health level 2 - Monitor\n",
        "    'schedule_maintenance': 3,  # Health level 3 - Schedule maintenance (80% threshold)\n",
        "    'urgent': 4          # Health level 4 - Urgent maintenance (60% threshold)\n",
        "}\n",
        "\n",
        "# Convert health levels to percentage scores (for visualization)\n",
        "def health_level_to_percentage(health_level):\n",
        "    \"\"\"Convert health level to percentage (higher is better)\"\"\"\n",
        "    mapping = {\n",
        "        0: 100,  # Excellent\n",
        "        2: 80,   # Good\n",
        "        3: 60,   # Fair - Schedule maintenance\n",
        "        4: 40    # Poor - Urgent\n",
        "    }\n",
        "    return mapping.get(health_level, 50)\n",
        "\n",
        "def get_alert_status(health_level):\n",
        "    \"\"\"Get alert status based on health level\"\"\"\n",
        "    if health_level == 0:\n",
        "        return \"OK\", \"green\"\n",
        "    elif health_level == 2:\n",
        "        return \"MONITOR\", \"yellow\"\n",
        "    elif health_level == 3:\n",
        "        return \"SCHEDULE MAINTENANCE\", \"orange\"\n",
        "    elif health_level >= 4:\n",
        "        return \"URGENT MAINTENANCE\", \"red\"\n",
        "    else:\n",
        "        return \"UNKNOWN\", \"gray\"\n",
        "\n",
        "print(\"\\nHealth Thresholds Defined:\")\n",
        "print(f\"  Excellent (100%): Health level 0 - No action needed\")\n",
        "print(f\"  Good (80%): Health level 2 - Monitor\")\n",
        "print(f\"  Schedule Maintenance (60%): Health level 3 - Schedule maintenance\")\n",
        "print(f\"  Urgent (40%): Health level 4 - Urgent maintenance required\")\n",
        "\n",
        "# ========================================\n",
        "# DASHBOARD: Health Score and Alerts\n",
        "# ========================================\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"DASHBOARD: Engine Oil Health Monitoring\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "\n",
        "# Create dashboard data\n",
        "dashboard_data = pd.DataFrame({\n",
        "    'actual_health': y_test[:50],  # Show first 50 samples\n",
        "    'predicted_health': y_pred[:50],\n",
        "    'health_percentage': [health_level_to_percentage(h) for h in y_pred[:50]]\n",
        "})\n",
        "\n",
        "# Add alert status\n",
        "dashboard_data['alert_status'] = dashboard_data['predicted_health'].apply(\n",
        "    lambda x: get_alert_status(x)[0]\n",
        ")\n",
        "dashboard_data['alert_color'] = dashboard_data['predicted_health'].apply(\n",
        "    lambda x: get_alert_status(x)[1]\n",
        ")\n",
        "\n",
        "# Create dashboard visualization\n",
        "fig = plt.figure(figsize=(16, 10))\n",
        "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "# 1. Health Score Distribution\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "health_counts = dashboard_data['predicted_health'].value_counts().sort_index()\n",
        "colors_map = {0: 'green', 2: 'yellow', 3: 'orange', 4: 'red'}\n",
        "colors_bar = [colors_map.get(h, 'gray') for h in health_counts.index]\n",
        "ax1.bar(health_counts.index, health_counts.values, color=colors_bar, alpha=0.7)\n",
        "ax1.set_xlabel('Health Level')\n",
        "ax1.set_ylabel('Count')\n",
        "ax1.set_title('Health Level Distribution')\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 2. Health Percentage Over Time (sample)\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "sample_indices = np.arange(len(dashboard_data))\n",
        "ax2.plot(sample_indices, dashboard_data['health_percentage'], marker='o',\n",
        "         linestyle='-', linewidth=2, markersize=4, color='steelblue')\n",
        "ax2.axhline(y=80, color='orange', linestyle='--', linewidth=2, label='Schedule Maintenance (80%)')\n",
        "ax2.axhline(y=60, color='red', linestyle='--', linewidth=2, label='Urgent (60%)')\n",
        "ax2.set_xlabel('Sample Index')\n",
        "ax2.set_ylabel('Health Percentage')\n",
        "ax2.set_title('Health Score Over Time (Sample)')\n",
        "ax2.set_ylim(0, 110)\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Alert Status Count\n",
        "ax3 = fig.add_subplot(gs[0, 2])\n",
        "alert_counts = dashboard_data['alert_status'].value_counts()\n",
        "alert_colors_list = [get_alert_status(\n",
        "    dashboard_data[dashboard_data['alert_status'] == status]['predicted_health'].iloc[0]\n",
        ")[1] for status in alert_counts.index]\n",
        "ax3.barh(alert_counts.index, alert_counts.values, color=alert_colors_list, alpha=0.7)\n",
        "ax3.set_xlabel('Count')\n",
        "ax3.set_title('Alert Status Distribution')\n",
        "ax3.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# 4. Health Percentage Histogram\n",
        "ax4 = fig.add_subplot(gs[1, :2])\n",
        "ax4.hist(dashboard_data['health_percentage'], bins=20, color='steelblue',\n",
        "         alpha=0.7, edgecolor='black')\n",
        "ax4.axvline(x=80, color='orange', linestyle='--', linewidth=2, label='Schedule Threshold (80%)')\n",
        "ax4.axvline(x=60, color='red', linestyle='--', linewidth=2, label='Urgent Threshold (60%)')\n",
        "ax4.set_xlabel('Health Percentage')\n",
        "ax4.set_ylabel('Frequency')\n",
        "ax4.set_title('Health Percentage Distribution')\n",
        "ax4.legend()\n",
        "ax4.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# 5. Current Status Summary\n",
        "ax5 = fig.add_subplot(gs[1, 2])\n",
        "ax5.axis('off')\n",
        "summary_text = f\"\"\"\n",
        "CURRENT STATUS SUMMARY\n",
        "{'=' * 30}\n",
        "\n",
        "Total Samples: {len(dashboard_data)}\n",
        "Excellent (100%): {len(dashboard_data[dashboard_data['predicted_health'] == 0])}\n",
        "Good (80%): {len(dashboard_data[dashboard_data['predicted_health'] == 2])}\n",
        "Schedule (60%): {len(dashboard_data[dashboard_data['predicted_health'] == 3])}\n",
        "Urgent (40%): {len(dashboard_data[dashboard_data['predicted_health'] == 4])}\n",
        "\n",
        "Average Health: {dashboard_data['health_percentage'].mean():.1f}%\n",
        "\n",
        "Alerts:\n",
        "  - Monitor: {len(dashboard_data[dashboard_data['alert_status'] == 'MONITOR'])}\n",
        "  - Schedule: {len(dashboard_data[dashboard_data['alert_status'] == 'SCHEDULE MAINTENANCE'])}\n",
        "  - Urgent: {len(dashboard_data[dashboard_data['alert_status'] == 'URGENT MAINTENANCE'])}\n",
        "\"\"\"\n",
        "ax5.text(0.1, 0.5, summary_text, fontsize=11, verticalalignment='center',\n",
        "         family='monospace', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "# 6. Sample Alert Table\n",
        "ax6 = fig.add_subplot(gs[2, :])\n",
        "ax6.axis('off')\n",
        "# Create a table of alerts\n",
        "alert_samples = dashboard_data[dashboard_data['predicted_health'] >= 3].head(10)\n",
        "if len(alert_samples) > 0:\n",
        "    table_data = []\n",
        "    for idx, row in alert_samples.iterrows():\n",
        "        table_data.append([\n",
        "            f\"Sample {idx}\",\n",
        "            f\"{row['health_percentage']:.0f}%\",\n",
        "            row['alert_status'],\n",
        "            f\"Level {row['predicted_health']}\"\n",
        "        ])\n",
        "    table = ax6.table(cellText=table_data,\n",
        "                     colLabels=['Sample ID', 'Health %', 'Alert Status', 'Health Level'],\n",
        "                     cellLoc='center',\n",
        "                     loc='center',\n",
        "                     bbox=[0, 0, 1, 1])\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(9)\n",
        "    table.scale(1, 2)\n",
        "    # Color code alert cells\n",
        "    for i in range(1, len(table_data) + 1):\n",
        "        status = table_data[i-1][2]\n",
        "        if 'URGENT' in status:\n",
        "            table[(i, 2)].set_facecolor('#ffcccc')\n",
        "        elif 'SCHEDULE' in status:\n",
        "            table[(i, 2)].set_facecolor('#ffe6cc')\n",
        "        elif 'MONITOR' in status:\n",
        "            table[(i, 2)].set_facecolor('#ffffcc')\n",
        "    ax6.set_title('Sample Alerts Requiring Action', fontsize=12, fontweight='bold', pad=20)\n",
        "else:\n",
        "    ax6.text(0.5, 0.5, 'No alerts in sample data', ha='center', va='center', fontsize=14)\n",
        "\n",
        "plt.suptitle('Engine Oil Health Monitoring Dashboard', fontsize=16, fontweight='bold', y=0.98)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print alert summary\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ALERT SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Total samples analyzed: {len(dashboard_data)}\")\n",
        "print(f\"  - OK (Excellent): {len(dashboard_data[dashboard_data['predicted_health'] == 0])}\")\n",
        "print(f\"  - Monitor: {len(dashboard_data[dashboard_data['alert_status'] == 'MONITOR'])}\")\n",
        "print(f\"  - Schedule Maintenance: {len(dashboard_data[dashboard_data['alert_status'] == 'SCHEDULE MAINTENANCE'])}\")\n",
        "print(f\"  - Urgent Maintenance: {len(dashboard_data[dashboard_data['alert_status'] == 'URGENT MAINTENANCE'])}\")\n",
        "print(f\"\\nAverage Health Score: {dashboard_data['health_percentage'].mean():.1f}%\")\n",
        "print(f\"Model Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}